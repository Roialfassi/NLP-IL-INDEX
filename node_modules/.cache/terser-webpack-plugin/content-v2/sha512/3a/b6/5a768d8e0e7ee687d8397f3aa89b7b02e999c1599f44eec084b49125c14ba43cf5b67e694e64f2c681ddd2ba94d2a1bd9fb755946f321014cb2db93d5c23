{"map":"{\"version\":3,\"sources\":[\"js/all-posts-vue.5a1a30a1.js\"],\"names\":[\"window\",\"push\",\"9a57\",\"module\",\"exports\",\"JSON\",\"parse\",\"a535\",\"__webpack_exports__\",\"__webpack_require__\",\"a9b5\",\"ae61\",\"r\",\"render\",\"_vm\",\"this\",\"_c\",\"_self\",\"_v\",\"staticClass\",\"directives\",\"name\",\"rawName\",\"value\",\"expression\",\"attrs\",\"type\",\"placeholder\",\"domProps\",\"on\",\"input\",\"$event\",\"target\",\"composing\",\"searchQuery\",\"change\",\"$$selectedVal\",\"Array\",\"prototype\",\"filter\",\"call\",\"options\",\"o\",\"selected\",\"map\",\"val\",\"_value\",\"selectedTag\",\"multiple\",\"filterItems\",\"_l\",\"tag\",\"_s\",\"item\",\"index\",\"key\",\"tags\",\"join\",\"href\",\"url\",\"duration\",\"enter\",\"leave\",\"mode\",\"description\",\"_e\",\"click\",\"toggleExpanded\",\"buttonText\",\"staticRenderFns\",\"all_postsvue_type_script_lang_js_\",\"[object Object]\",\"expanded\",\"items\",\"computed\",\"withButtons\",\"toLowerCase\",\"includes\",\"sites\",\"methods\",\"itemToFind\",\"find\",\"dictionary\",\"views_all_postsvue_type_script_lang_js_\",\"componentNormalizer\",\"component\",\"Object\"],\"mappings\":\"CAACA,OAAO,gBAAkBA,OAAO,iBAAmB,IAAIC,KAAK,CAAC,CAAC,iBAAiB,CAE1EC,OACA,SAAUC,GAEhBA,EAAOC,QAAUC,KAAKC,MAAM,mk2CAItBC,KACA,SAAUJ,EAAQK,EAAqBC,GAE7C,aACocA,EAAoB,SAOldC,KACA,SAAUP,EAAQC,EAASK,KAM3BE,KACA,SAAUR,EAAQK,EAAqBC,GAE7C,aAEAA,EAAoBG,EAAEJ,GAGtB,IAAIK,EAAS,WAAkB,IAAIC,EAAIC,KAAKC,EAAGF,EAAIG,MAAMD,GAAG,OAAOA,EAAG,MAAM,CAACA,EAAG,KAAK,CAACF,EAAII,GAAG,0BAA0BF,EAAG,MAAM,CAACG,YAAY,WAAW,CAACH,EAAG,QAAQ,CAACF,EAAII,GAAG,mCAAmCF,EAAG,QAAQ,CAACI,WAAW,CAAC,CAACC,KAAK,QAAQC,QAAQ,UAAUC,MAAOT,EAAe,YAAEU,WAAW,gBAAgBC,MAAM,CAACC,KAAO,OAAOC,YAAc,gBAAgBC,SAAS,CAACL,MAAST,EAAe,aAAGe,GAAG,CAACC,MAAQ,SAASC,GAAWA,EAAOC,OAAOC,YAAiBnB,EAAIoB,YAAYH,EAAOC,OAAOT,aAAYP,EAAG,MAAMA,EAAG,QAAQ,CAACF,EAAII,GAAG,kCAAkCF,EAAG,SAAS,CAACI,WAAW,CAAC,CAACC,KAAK,QAAQC,QAAQ,UAAUC,MAAOT,EAAe,YAAEU,WAAW,gBAAgBK,GAAG,CAACM,OAAS,CAAC,SAASJ,GAAQ,IAAIK,EAAgBC,MAAMC,UAAUC,OAAOC,KAAKT,EAAOC,OAAOS,SAAQ,SAASC,GAAG,OAAOA,EAAEC,YAAWC,KAAI,SAASF,GAAG,IAAIG,EAAM,WAAYH,EAAIA,EAAEI,OAASJ,EAAEnB,MAAM,OAAOsB,KAAO/B,EAAIiC,YAAYhB,EAAOC,OAAOgB,SAAWZ,EAAgBA,EAAc,IAAItB,EAAImC,eAAe,CAACjC,EAAG,SAAS,CAACS,MAAM,CAACF,MAAQ,QAAQ,CAACT,EAAII,GAAG,SAASJ,EAAIoC,GAAIpC,EAAQ,MAAE,SAASqC,GAAK,OAAOnC,EAAG,SAAS,CAACY,SAAS,CAACL,MAAQ4B,IAAM,CAACrC,EAAII,GAAGJ,EAAIsC,GAAGD,UAAW,KAAKnC,EAAG,QAAQA,EAAG,MAAM,CAACG,YAAY,iBAAiBL,EAAIoC,GAAIpC,EAAkB,gBAAE,SAASuC,EAAKC,GAAO,OAAOtC,EAAG,MAAM,CAACuC,IAAIF,EAAKhC,KAAKF,YAAY,QAAQ,CAACH,EAAG,KAAK,CAACG,YAAY,aAAa,CAACL,EAAII,GAAGJ,EAAIsC,GAAGC,EAAKhC,SAASL,EAAG,IAAI,CAACF,EAAII,GAAGJ,EAAIsC,GAAGC,EAAKG,KAAKC,KAAK,UAAUzC,EAAG,IAAI,CAACG,YAAY,YAAYM,MAAM,CAACiC,KAAOL,EAAKM,IAAI3B,OAAS,WAAW,CAAClB,EAAII,GAAG,oBAAoBF,EAAG,MAAMA,EAAG,MAAMA,EAAG,MAAM,CAACA,EAAG,aAAa,CAACS,MAAM,CAACmC,SAAW,CAAEC,MAAO,IAAKC,MAAO,KAAMzC,KAAO,OAAO0C,KAAO,WAAW,CAAEV,EAAa,SAAErC,EAAG,MAAM,CAACG,YAAY,cAAc,CAACL,EAAII,GAAG,iBAAiBJ,EAAIsC,GAAGC,EAAKW,aAAa,kBAAkBhD,EAAG,MAAMA,EAAG,QAAQF,EAAImD,OAAOjD,EAAG,SAAS,CAACG,YAAY,gBAAgBU,GAAG,CAACqC,MAAQ,SAASnC,GAAQ,OAAOjB,EAAIqD,eAAed,EAAKhC,SAAS,CAACP,EAAII,GAAGJ,EAAIsC,GAAGC,EAAKe,gBAAgB,QAAO,MAEv4DC,EAAkB,GAOWC,EAAoC,CACnEC,OACE,MAAO,CACLrC,YAAa,GACbsC,UAAU,EACVC,MAAO,GAEPjB,KAAM,CAAC,UAAW,OAAQ,uBAAwB,SAAU,qCAAsC,iBAClGT,YAAa,QAGjB2B,SAAU,CACRH,iBACE,IAAII,EAAc5D,KAAK0D,MAAM7B,IAAKS,IACzB,IACFA,EACHe,WAAYf,EAAKmB,SAAW,WAAa,YAI7C,OADAG,EAAcA,EAAYpC,OAAOc,GAAQA,EAAKhC,KAAKuD,cAAcC,SAAS9D,KAAKmB,YAAY0C,gBAClE,QAArB7D,KAAKgC,YACA4B,EAEFA,EAAYpC,OAAOc,GAAQA,EAAKG,KAAKqB,SAAS9D,KAAKgC,gBAI9DwB,cACE,IAAIO,EAAQrE,EAAoB,QAAQmC,IAAIe,IAAO,IAAMA,EAAKa,UAAU,KACxEzD,KAAK0D,MAAQK,GAEfC,QAAS,CACPR,gBAGAA,eAAelD,GACb,MAAM2D,EAAajE,KAAK0D,MAAMQ,KAAKC,GAAcA,EAAW7D,OAASA,GACrE2D,EAAWR,UAAYQ,EAAWR,YAMNW,EAA0C,EAKxEC,GAH6D3E,EAAoB,QAG3DA,EAAoB,SAW1C4E,EAAYC,OAAOF,EAAoB,KAA3BE,CACdH,EACAtE,EACAwD,GACA,EACA,KACA,KACA,MAI2C7D,EAAoB,WAAc6E,EAAiB\"}","code":"(window[\"webpackJsonp\"]=window[\"webpackJsonp\"]||[]).push([[\"all-posts-vue\"],{\"9a57\":function(e){e.exports=JSON.parse('[{\"name\":\"Hebrew Wikipedia dumps\",\"tags\":[\"Corpora\",\"Structured Corpora\",\"Unannotated Corpora\"],\"description\":\"Wikipedia, the free encyclopedia, publishes dumps of its content as XML files on a monthly basis.\",\"url\":\"https://dumps.wikimedia.org/hewiki/latest/\"},{\"name\":\"hewikibooks dump\",\"tags\":[\"Corpora\",\"Structured Corpora\",\"Unannotated Corpora\"],\"description\":\"Wikimedia dump service\",\"url\":\"https://dumps.wikimedia.org/hewikibooks/20220520/\"},{\"name\":\"Wikipedia Corpora used for AlephBERT\",\"tags\":[\"Corpora\",\"Structured Corpora\",\"Unannotated Corpora\"],\"description\":\"The texts in all of Hebrew Wikipedia was also extracted to pre-train OnlpLab\\'s AlephBERT, using `Attardi\\'s Wikiextractor\",\"url\":\"https://github.com/OnlpLab/AlephBERT/tree/main/data/wikipedia\"},{\"name\":\"OSCAR\",\"tags\":[\"Corpora\",\"Structured Corpora\",\"Unannotated Corpora\"],\"description\":\"OSCAR or Open Super-large Crawled Aggregated coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the Ungoliant architecture.\",\"url\":\"https://oscar-corpus.com/\"},{\"name\":\"Project Ben Yehuda public dumps\",\"tags\":[\"Corpora\",\"Structured Corpora\",\"Unannotated Corpora\"],\"description\":\"A repository containing dumps of thousands of public domain works in Hebrew, from `Project Ben-Yehuda, in plaintext UTF-8 files, with and without diacritics (nikkud), and in HTML files.\",\"url\":\"https://github.com/projectbenyehuda/public_domain_dump\"},{\"name\":\"CC100\",\"tags\":[\"Corpora\",\"Structured Corpora\",\"Unannotated Corpora\"],\"description\":\"This corpus is an attempt to recreate the dataset used for training XLM-R. This corpus comprises of monolingual data for 100+ languages, including Hebrew. This was constructed using the urls and paragraph indices provided by the CC-Net repository by processing January-December 2018 Commoncrawl snapshots.\",\"url\":\"https://data.statmt.org/cc-100/?fbclid=IwAR2czQ8iHkINcK3oAoYTtIRcsj0TaiKOedor6S3Xzb-9-djTnHrK5D69lD0\"},{\"name\":\"Sefaria\",\"tags\":[\"Corpora\",\"Structured Corpora\",\"Unannotated Corpora\"],\"description\":\"Structured Jewish texts and metadata with free public licenses, exported from Sefaria\\'s database.\",\"url\":\"https://github.com/Sefaria/Sefaria-Export/\"},{\"name\":\"Hebrew songs lyrics\",\"tags\":[\"Corpora\",\"Structured Corpora\",\"Unannotated Corpora\"],\"description\":\"15,000 israeli songs scrapped from `Shironet`_ website and contains 167 different singers. Contains only hebrew charecters.\",\"url\":\"https://www.kaggle.com/datasets/guybarash/hebrew-songs-lyrics?fbclid=IwAR1Tji-2oWxeB54wM3YDVViMG7xTM6000yiov_H1AZTQVRiP9VfmiXkyYu4\"},{\"name\":\"Knesset 2004-2005\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Annotated by Parts of Speech\"],\"description\":\"A corpus of transcriptions of Knesset (Israeli parliament) meetings between January 2004 and November 2005. Includes tokenized and morphologically tagged versions of most of the documents in the corpus.\",\"url\":\"https://github.com/NLPH/knesset-2004-2005\"},{\"name\":\"The GOV.il Corpus\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Annotated by Parts of Speech\"],\"description\":\" קורפוס השפה העברית -    מאגר שפה מתויגת, חלק מפרוייקט קורפוס השפה העברית של רשות התקשוב הממשלתי. התיוג מבוצע על ידי האקדמיה ללשון העברית. תוצר ראשון זה כולל 600 משפטים מתוייגים\",\"url\":\"https://data.gov.il/dataset/corpus\"},{\"name\":\"NEMO\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Annotated by Entites\"],\"description\":\"Named Entity (NER) annotations of the Hebrew Treebank (Haaretz newspaper) corpus, including: morpheme and token level NER labels, nested mentions, and more. The following entity types are tagged: Person, Organization, Geo-Political Entity, Location, Facility, Work-of-Oart, Event, Product, Language.\",\"url\":\"https://github.com/OnlpLab/NEMO-Corpus\"},{\"name\":\"MDTEL\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Annotated by Entites\"],\"description\":\"A dataset of posts from the www.camoni.co.il, tagged with medical entities from the UMLS, and a code that recognize medical entities in the Hebrew text.\",\"url\":\"https://github.com/yonatanbitton/mdtel?fbclid=IwAR3Npi5lG4hGy1dcQwdr2RWuEFUArjmQ_bo3FXQ9KhYZUpK5OO67-aT-e5k\"},{\"name\":\"Ben-Mordecai and Elhadad\\'s Corpus\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Annotated by Entites\"],\"description\":\"Newspaper articles in different fields: news, economy, fashion and gossip. The following entity types are tagged: entity names (person, location, organization), temporal experssion (date, time) and number experession (percent, money).\",\"url\":\"https://www.cs.bgu.ac.il/~elhadad/nlpproj/naama/\"},{\"name\":\"ParaShoot\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Question Answering Datasets\"],\"description\":\"A Hebrew question and answering dataset in the style of SQuAD created by Omri Keren and Omer Levy. ParaShoot is based on articles scraped from Wikipedia. The dataset contains 3K crowdsource-annotated pairs of questions and answers, in a setting suitable for few-shot learning.\",\"url\":\"https://github.com/omrikeren/ParaShoot\"},{\"name\":\"tdklab\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Question Answering Datasets\"],\"description\":\"translated (by google translation API) SQUAD dataset from English to Hebrew. The translation process included fixation and removal of bad translations.\",\"url\":\"https://github.com/TechnionTDK/hebwiki-qa?fbclid=IwAR0Xbq-s1xu2gH8BS35zgFgNCeHIJ6wVZws4gqHCZ_VucbgiIngpHNTWApU\"},{\"name\":\"Hebrew-Sentiment-Data Amram et al\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Sentiment\"],\"description\":\"A sentiment analysis benchmark (positive, negative and neutral sentiment) for Hebrew, based on 12K social media comments, containing two instances of input items: token-based and morpheme-based. A cleaned version of the Hebrew Sentiment dataset - a test-train data leakage was cleaned.\",\"url\":\"https://github.com/OnlpLab/Hebrew-Sentiment-Data>\"},{\"name\":\"Emotion User Generated Content (UGC)\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Sentiment\"],\"description\":\"{MIT} - collected for HeBERT model and includes comments posted on news articles collected from 3 major Israeli news sites, between January 2020 to August 2020. The total size of the data is ~150 MB, including over 7 millions words and 350K sentences. ~2000 sentences were annotated by crowd members (3-10 annotators per sentence) for overall sentiment (polarity) and eight emotions.\",\"url\":\"https://github.com/avichaychriqui/HeBERT?fbclid=IwAR0GVuSWEvYWimkV4Z22h6-GSEznY2G2eIRz7gDGcAcHT3hB4vgUkxkBCPg\"},{\"name\":\"Emotion User Generated Content\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Emotion\"],\"description\":\"{MIT} - collected for HeBERT model and includes comments posted on news articles collected from 3 major Israeli news sites, between January 2020 to August 2020. The total size of the data is ~150 MB, including over 7 millions words and 350K sentences. ~2000 sentences were annotated by crowd members (3-10 annotators per sentence) for overall sentiment (polarity) and eight emotions: anger, disgust, expectation , fear, happy, sadness, surprise and trust.\",\"url\":\"https://github.com/avichaychriqui/HeBERT?fbclid=IwAR0GVuSWEvYWimkV4Z22h6-GSEznY2G2eIRz7gDGcAcHT3hB4vgUkxkBCPg\"},{\"name\":\"Knesset Topic Classification\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Topic Classification\"],\"description\":\"This data was collected as a part of Nitzan Barzilay\\'s project and contains about 2,700 quotes from Knesset meetings, manually classified into eight topics: education, Covid-19, welfare, economic, women and LGBT, health, security, internal security.\",\"url\":\"https://github.com/NitzanBarzilay/KnessetTopicClassification/\"},{\"name\":\"The HUJI Corpus of Spoken Hebrew\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Recorded Spoken Hebrew\"],\"description\":\"The corpus project, created by Dr Michal Marmorstein, Nadav Matalon, Amir Efrati, Itamar Folman and Yuval Geva, and hosted by the Hebrew University of Jerusalem (HUJI), aims at documenting naturally occurring speech and interaction in Modern Hebrew. Data come from telephone conversations recorded during the years 2020–2021. Data annotation followed standard methods of Interactional Linguistics (Couper-Kuhlen and Selting 2018). Audio files and transcripts were made freely accessible online.\",\"url\":\"https://huji-corpus.com/\"},{\"name\":\"CoSIH - The Corpus of Spoken Hebrew\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Recorded Spoken Hebrew\"],\"description\":\"The Corpus of Spoken Israeli Hebrew (CoSIH) is a database of recordings of spoken Israeli Hebrew\",\"url\":\"http://cosih.com/table-3.html\"},{\"name\":\"MaTaCOp\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Recorded Spoken Hebrew\"],\"description\":\"a corpus of Hebrew dialogues within the Map Task framework (allowed for non-commercial research and teaching purposes only)\",\"url\":\"https://www.openu.ac.il/en/academicstudies/matacop/pages/default.aspx\"},{\"name\":\"Eran Tomer\\'s Digital Vocalized Text Corpus\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Other Datasets\"],\"description\":\"A corpus of digital vocalized Hebrew texts created by Eran Tomer as part of his Master thesis. The corpus is found in the ``resources`` folder.\",\"url\":\"https://www.dropbox.com/sh/rlg0k0flz0675ho/AADvfxmY3SN8lqmkGAWr0hd2a?dl=0\"},{\"name\":\"The SVLM Hebrew Wikipedia Corpus\",\"tags\":[\"Corpora\",\"Annotated Datasets\",\"Other Datasets\"],\"description\":\"A corpus of 50K sentences from Hebrew Wikipedia chosen to ensure phoneme coverage for the purpose of a sentence recording project.\",\"url\":\"https://github.com/NLPH/SVLM-Hebrew-Wikipedia-Corpus\"},{\"name\":\"The MILA corpora collection\",\"tags\":[\"Corpora\",\"Corpora Sources\"],\"description\":\"The MILA center has 20 different corpora available for free for non-commercial use. All are available in plain text format, and most have tokenized, morphologically-analyzed, and morphologically-disambiguated versions available too.\",\"url\":\"http://www.mila.cs.technion.ac.il/resources_corpora.html\"},{\"name\":\"JPress\",\"tags\":[\"Corpora\",\"Corpora Sources\"],\"description\":\"`The National Library http://web.nli.org.il offers a collection of Jewish newspapers published in various countries, languages, and time periods, including digital versions and full-text search. The texts are published under a custom Terms of Use document that prohibits commercial use, and additionally requires checking the copyright status and receiving permission from the copyright-holder of the work for any use requiring such permission according to the Copyright Law.\",\"url\":\"http://www.jpress.org.il\"},{\"name\":\"DICTA\",\"tags\":[\"Corpora\",\"Corpora Sources\"],\"description\":\"Analytical tools for Jewish texts. They also have a `GitHub organization`\",\"url\":\"http://dicta.org.il\"},{\"name\":\"Sefaria Corpra\",\"tags\":[\"Corpora\",\"Corpora Sources\"],\"description\":\"{Various} - A Living Library of Jewish Texts. 3,000 years of Jewish texts in Hebrew and English translation.\",\"url\":\"https://www.sefaria.org.il/\"},{\"name\":\"HaArchion\",\"tags\":[\"Corpora\",\"Corpora Sources\"],\"description\":\"Recording of various Hebrew prose and poetry being read.\",\"url\":\"http://www.haarchion.co.il/\"},{\"name\":\"ThinkIL\",\"tags\":[\"Corpora\",\"Corpora Sources\"],\"description\":\"An archive of the writings of Zvi Yanai.\",\"url\":\"http://thinkil.co.il/the-website/credits_and_sponsors/\"},{\"name\":\"The MILA lexicon of Hebrew words\",\"tags\":[\"Linguistic Resources\",\"Lexicons \"],\"description\":\"The lexicon was designed mainly for usage by morphological analyzers, but is being constantly extended to facilitate other applications as well. The lexicon contains about 25,000 lexicon items and is extended regularly. Free for non-commercial use.\",\"url\":\"http://www.mila.cs.technion.ac.il/resources_lexicons_mila.html\"},{\"name\":\"Hebrew WordNet\",\"tags\":[\"Linguistic Resources\",\"Lexicons \"],\"description\":\"Hebrew WordNet uses the MultiWordNet methodology and is aligned with the one developed at IRST (and therefore is aligned with English, Italian and Spanish). Free for non-commercial use.\",\"url\":\"http://www.mila.cs.technion.ac.il/resources_lexicons_wordnet.html\"},{\"name\":\"MILA\\'s Verb Complements Lexicon\",\"tags\":[\"Linguistic Resources\",\"Lexicons \"],\"description\":\"MILA\\'s Verb Complements Lexicon\",\"url\":\"http://www.mila.cs.technion.ac.il/resources_lexicons_verbcomplements.html\"},{\"name\":\"Hebrew Psychological Lexicons\",\"tags\":[\"Linguistic Resources\",\"Lexicons \"],\"description\":\"Natalie Shapira\\'s large collection of Hebrew psychological lexicons and word lists. Useful for various psychology applications such as detecting emotional state, well being, relationship quality in conversation, identifying topics (e.g., family, work) and many more.\",\"url\":\"https://github.com/natalieShapira/HebrewPsychologicalLexicons?fbclid=IwAR20aH6v8MY9rZH9H03-DetxPYVEjispaH5n2Zrs-rSnjOFyv4zNiawlpIU\"},{\"name\":\"MILA\\'s Hebrew Stopwords List\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\"An Excel XLSX file containing 23,327 Hebrew tokens in descending order of frequency.\",\"url\":\"http://www.mila.cs.technion.ac.il/resources_lexicons_stopwords.html\"},{\"name\":\"Tapuz Hebrew Stop Words\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\"a list of the 500 most common words (stop words) computed from discussions from the Tapuz People website, on a variety of subjects.\",\"url\":\"https://www.kaggle.com/datasets/danofer/hebrew-stop-words?fbclid=IwAR2DpSsgJuYyPdaJ9K2WUpZY324pjkXOAuWKv4sUhgkZVjY7n6ej6UK7pwQ\"},{\"name\":\"Hebrew verb lists\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\"Created by Eran Tomer (erantom@gmail.com).\",\"url\":\"https://github.com/NLPH/NLPH_Resources/tree/master/linguistic_resources/word_lists/hebrew_verbs_eran_tomer\"},{\"name\":\"Hebrew name lists\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\" Lists of street, company, given and last names. Created by Guy Laybovitz.\",\"url\":\"https://github.com/NLPH/NLPH_Resources/tree/master/linguistic_resources/word_lists/dday\"},{\"name\":\"1000 most frequent words in Hebrew tweets during (roughly) 2018\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\"\",\"url\":\"https://github.com/NLPH/NLPH_Resources/blob/master/linguistic_resources/word_lists/top_1000_hebrew_words_twitter_2018.txt\"},{\"name\":\"`KIMA - the Historical Hebrew Gazetteer\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\"Place Names in the Hebrew Script. An open, attestation based, historical database. Kima currently holds 27,239 Places, with 94,650 alternate variants of their names and 236,744 attestations of these variants.\",\"url\":\"http://data.geo-kima.org/\"},{\"name\":\"Wikidata Lexemes\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\"Uploaded by Uziel302\",\"url\":\"http://query.wikidata.org/\"},{\"name\":\"Hebrew most common words by Twitter\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\"based on tweets from March 2018 to March 2019.\",\"url\":\"https://github.com/YontiLevin/Hebrew-most-common-words-by-Twitter?fbclid=IwAR2oZcojNddFzs4Cd6cMI-Zyp1Mh8h2s2Ih61mQ3vQMDyw-2wf6Dd3DmIMw\"},{\"name\":\"wordfreq\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\"wordfreq is a Python library for looking up the frequencies of words in 44 languages, including Hebrew. The Hebrew data is based on Wikipedia, OPUS OpenSubtitles 2018 and SUBTLEX, Google Books Ngrams 2012, Web text from OSCAR and Twitter.\",\"url\":\"https://pypi.org/project/wordfreq/?fbclid=IwAR0XRlwXQlzbrVoodjatJTrcKwnxvoA4dVBSZyiQuB-qEzXAiizDX63hLGc\"},{\"name\":\"Hebrew WordLists\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\"Useful word lists extracted from Hspell 1.4 by Eyal Gruss.\",\"url\":\"https://github.com/eyaler/hebrew_wordlists?fbclid=IwAR3QlqD_MDPxhiK7IktW7Sp8fnlgANT3TCYX6R_Rg_gzK9t8vXAqDuAbP90\"},{\"name\":\"Hebrew stop word base on the UD\",\"tags\":[\"Linguistic Resources\",\"Dictionaries & Word Lists\"],\"description\":\"List of stop words in Hebrew produced by using Universal Dependencies of the The Israeli Association of Human Language Technologies (IAHLT)\",\"url\":\"https://github.com/NNLP-IL/Stop-Words-Hebrew\"},{\"name\":\"The Hebrew Treebank\",\"tags\":[\"Linguistic Resources\",\"Treebanks\"],\"description\":\"The Hebrew Treebank Version 2.0 contains 6500 hand-annotated sentences of news items from the MILA HaAretz Corpus, with full word segmentation and morpho-syntactic analysis. Morphological features that are not directly relevant for syntactic structures, like roots, templates and patterns, are not analyzed. This resource can be used freely for research purposes only.\",\"url\":\"http://www.mila.cs.technion.ac.il/resources_treebank.html\"},{\"name\":\"UD Hebrew Treebank\",\"tags\":[\"Linguistic Resources\",\"Treebanks\"],\"description\":\"The Hebrew Universal Dependencies Treebank.\",\"url\":\"https://github.com/UniversalDependencies/UD_Hebrew\"},{\"name\":\"Modern Hebrew Dependency Treebank v.1\",\"tags\":[\"Linguistic Resources\",\"Treebanks\"],\"description\":\"This is the Modern Hebrew Dependency Treebank which was created and used in Yoav Goldberg\\'s `PhD thesis http://www.cs.bgu.ac.il/~nlpproj/yoav-phd.pdf\",\"url\":\"https://www.cs.bgu.ac.il/~yoavg/data/hebdeptb/\"},{\"name\":\"UD Hebrew IAHLTwiki\",\"tags\":[\"Linguistic Resources\",\"Treebanks\"],\"description\":\"Publicly available subset of the IAHLT UD Hebrew Treebank\\'s Wikipedia section. The UD Hebrew-IAHLTWiki treebank consists of 5,000 contemporary Hebrew sentences representing a variety of texts originating from Wikipedia entries, compiled by the Israeli Association of Human Language Technology. It includes various text domains, such as: biography, law, finance, health, places, events and miscellaneous.\",\"url\":\"https://github.com/UniversalDependencies/UD_Hebrew-IAHLTwiki\"},{\"name\":\"fastText pre-trained word vectors\",\"tags\":[\"Linguistic Resources\",\"Embeddings\"],\"description\":\"Trained on `Wikipedia <https://www.wikipedia.org/>`_ using `fastText <https://github.com/facebookresearch/fastText>`_. Comes in both the binary and text default formats of fastText: `binary+text <https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.he.zip>`_, `text <https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.he.vec>`_. In the text format, each line contains a word followed by its embedding; Each value is space separated; Words are ordered by their frequency in a descending order.\",\"url\":\"https://github.com/facebookresearch/fastText/blob/master/docs/pretrained-vectors.md\"},{\"name\":\"hebrew-word2vec pre-trained word vectors\",\"tags\":[\"Linguistic Resources\",\"Embeddings\"],\"description\":\"Trained on data from Twitter. Developed by Ron Shemesh in Bar-Ilan University\\'s NLP lab under the instruction of Dr. Yoav Goldberg. Contains vectors for over 1.4M words (as of January 2018). Comes in a zip with two files: a text file with a word list and a NumPy array file (npy file).\",\"url\":\"<https://github.com/Ronshm/hebrew-word2vec\"},{\"name\":\"CoNLL17 word2vec word embeddings\",\"tags\":[\"Linguistic Resources\",\"Embeddings\"],\"description\":\"Trained on the Hebrew CoNLL17 corpus using Word2Vec continuous skipgram, with a vecotor dimension of 100 and a window size of 10. The vocabulary includes 672,384 words.\",\"url\":\"http://vectors.nlpl.eu/repository/\"},{\"name\":\"CoNLL17 ELMO word embeddings\",\"tags\":[\"Linguistic Resources\",\"Embeddings\"],\"description\":\"Trained on the Hebrew CoNLL17 corpus using ELMO. **NOTE:** The link at the repository might not work. To download a concerete version of the Hebrew embeddings, `press here <http://vectors.nlpl.eu/repository/20/154.zip>`_.\",\"url\":\"https://github.com/ltgoslo/simple_elmo/\"},{\"name\":\"Hebrew Word Embeddings by Lior Shkiller\",\"tags\":[\"Linguistic Resources\",\"Embeddings\"],\"description\":\"Read more in `this blog post <https://www.oreilly.com/learning/capturing-semantic-meanings-using-deep-learning>`_.\",\"url\":\"https://github.com/liorshk/wordembedding-hebrew\"},{\"name\":\"Hebrew Subword Embeddings\",\"tags\":[\"Linguistic Resources\",\"Embeddings\"],\"description\":\"\",\"url\":\"https://nlp.h-its.org/bpemb/he/\"},{\"name\":\"LASER Language-Agnostic SEntence Representations\",\"tags\":[\"Linguistic Resources\",\"Embeddings\"],\"description\":\"LASER is a library to calculate and use multilingual sentence embeddings.\",\"url\":\"https://github.com/facebookresearch/LASER\"},{\"name\":\"Multilingual BERT\",\"tags\":[\"Linguistic Resources\",\"Embeddings\"],\"description\":\"BERT, or Bidirectional Encoder Representations from Transformers, is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks.\",\"url\":\"https://github.com/google-research/bert/blob/master/multilingual.md?fbclid=IwAR3Tm1UQjzZtz0XcH7NsR5DvWqfxDxuc3DJkxwmWpwZtkYXFC2bc5HRut_0\"},{\"name\":\"hebrew-w2v\",\"tags\":[\"Linguistic Resources\",\"Embeddings\"],\"description\":\"Iddo Yadlin and Itamar Shefi\\'s word2vec model for Hebrew, trained on a corpus which is the Hebrew wikipedia dump only tokenized with hebpipe.\",\"url\":\"https://github.com/Iddoyadlin/hebrew-w2v?fbclid=IwAR3QIwzgcziyANpq8-YEPeO1eQzBboDCLeIiSPnenqrFEedCNCgB3QEo44o\"},{\"name\":\"Hebrew SimLex-999 \",\"tags\":[\"Linguistic Resources\",\"Other Resources\"],\"description\":\"A Hebrew version of the `Simlex-999 <https://fh295.github.io/simlex.html>`_ resource for the evaluation of models that learn the meaning of words and concepts. A copy can also be found in the `Attract-Repel repository <https://github.com/nmrksic/attract-repel>`_. Another copy is found in `this repository <https://github.com/NLPH/NLPH_Resources/tree/master/linguistic_resources/other/hebrew_simlex-999>`_.\",\"url\":\"https://drive.google.com/drive/folders/0B_pyA_IW4g-jTlJzOHlSWVZWbTQ\"},{\"name\":\"שתי שקל\",\"tags\":[\"Linguistic Resources\",\"Other Resources\"],\"description\":\"Wikiproject for correcting grammar mistakes. (Heuristic) positive annotions can be derived from  `query <https://quarry.wmflabs.org/query/21957>`_.\",\"url\":\"https://he.wikipedia.org/wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94:%D7%AA%D7%97%D7%96%D7%95%D7%A7%D7%94/%D7%A9%D7%AA%D7%99_%D7%A9%D7%A7%D7%9C\"},{\"name\":\"The Word-Frequency Database for Printed Hebrew\",\"tags\":[\"Linguistic Resources\",\"Other Resources\"],\"description\":\"supplies the frequency of occurrence of any Hebrew letter cluster (mean occurrence per million). The corpus was assembled throughout the year 2001, and consists of text downloaded from 914 editions of the three major daily online Hebrew newspapers (Haaretz, Maariv, and Yediot Acharonot). After removing abbreviations, single characters, forms with counts that are less than 3 (mostly typos), and splitting hyphenated forms (vast majority were two words), the corpus totals 554,270 types and 619,835,788 tokens.\",\"url\":\"http://word-freq.huji.ac.il/index.html?fbclid=IwAR2Bl_-8eNKmxUBts1S3hipWm63_0TSPk3lmweVW1q5XcblmezjtREWS24s\"},{\"name\":\"awesome-hebrew-nlp iddo berger\",\"tags\":[\"Code\"],\"description\":\"More NLP awesome stuff by iddo berger\",\"url\":\"https://github.com/iddoberger/awesome-hebrew-nlp\"},{\"name\":\"Yonti Levin\\'s Hebrew Tokenizer\",\"tags\":[\"Code\",\"Tokenization\"],\"description\":\"python\",\"url\":\"https://github.com/YontiLevin/Hebrew-Tokenizer\"},{\"name\":\"Hebrew Tokenizer\",\"tags\":[\"Code\",\"\",\"Tokenization\"],\"description\":\" Eyal Gruss\\'s Hebrew tokenizer. A field-tested Hebrew tokenizer for dirty texts (ben-yehuda project, bible, cc100, mc4, opensubs, oscar, twitter) focused on multi-word expression extraction.\",\"url\":\"https://github.com/eyaler/hebrew_tokenizer?fbclid=IwAR1vbBpU9SOzQ71ZaxAjyBwNVuyhuYs3dMQsAUlZXCINy4TSg2BVWvoBARc\"},{\"name\":\"Morphological and Syntactic Analysis of Hebrew Texts by ONLP\",\"tags\":[\"Code\",\"Morphological and Syntactic Analysis\"],\"description\":\"\",\"url\":\"https://nlp.biu.ac.il/~rtsarfaty/onlp/hebrew/\"},{\"name\":\"yap morpho-syntactic parser\",\"tags\":[\"Code\",\"Morphological and Syntactic Analysis\"],\"description\":\"Morphological Analysis, disambiguation and dependency Parser. Morphological Analyzer relies on the BGU Lexicon. [`original repository <http://github.com/habeanf/yap>`_]\",\"url\":\"https://github.com/OnlpLab/yap\"},{\"name\":\"The MILA Morphological Analysis Tool\",\"tags\":[\"Code\",\"Morphological and Syntactic Analysis\"],\"description\":\"Takes as input undotted Hebrew text (formatted either as plain text or as tokenized XML following MILA\\'s standards). The Analyzer then returns, for each token, all the possible morphological analyses of the token, reflecting part of speech, transliteration, gender, number, definiteness, and possessive suffix. Free for non-commercial use. \",\"url\":\"http://www.mila.cs.technion.ac.il/tools_analysis.html\"},{\"name\":\"The MILA Morphological Disambiguation Tool\",\"tags\":[\"Code\",\"Morphological and Syntactic Analysis\"],\"description\":\"Takes as input morphologically-analyzed text and uses a Hidden Markov Model (HMM) to assign scores for each analysis, considering contextual information from the rest of the sentence. For a given token, all analyses deemed impossible are given scores of 0; all n analyses deemed possible are given positive scores. Free for non-commercial use.\",\"url\":\"http://www.mila.cs.technion.ac.il/tools_disambiguation.html\"},{\"name\":\"Hspell\",\"tags\":[\"Code\",\"Morphological and Syntactic Analysis\"],\"description\":\"Free Hebrew linguistic project including spell checker and  morphological analyzer.\",\"url\":\"http://hspell.ivrix.org.il/\"},{\"name\":\"HspellPy\",\"tags\":[\"Code\",\"Morphological and Syntactic Analysis\"],\"description\":\"Python wrapper for hspell.\",\"url\":\"https://github.com/eranroz/HspellPy/\"},{\"name\":\"BGU Tagger: Morphological Tagging of Hebrew\",\"tags\":[\"Code\",\"Morphological and Syntactic Analysis\"],\"description\":\"Morphological Analysis, Disambiguation.\",\"url\":\"https://www.cs.bgu.ac.il/~elhadad/nlp12/hebrew/TagHebrew.html\"},{\"name\":\"RFTokenizer\",\"tags\":[\"Code\",\"Morphological and Syntactic Analysis\"],\"description\":\"A highly accurate morphological segmenter to break up complex word forms\",\"url\":\"https://github.com/amir-zeldes/RFTokenizer\"},{\"name\":\"HebPipe\",\"tags\":[\"Code\",\"Morphological and Syntactic Analysis\"],\"description\":\"End-to-end pipeline for Hebrew NLP using off the shelf tools, including morphological analysis, tagging, lemmatization, parsing and more\",\"url\":\"https://github.com/amir-zeldes/HebPipe\"},{\"name\":\"Nakdan\",\"tags\":[\"Code\",\"Diacritization / Nikkud / Vocalization\"],\"description\":\"(`Paper <https://aclanthology.org/2020.acl-demos.23.pdf>`_) - Tool for Automatic and semi-automatic Nikud for Hebrew texts. Avi Shmidman, Shaltiel Shmidman, Moshe Koppel, and Yoav Goldberg. 2020. Nakdan: Professional Hebrew diacritizer. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 197–203, Online. Association for Computational Linguistics.\",\"url\":\"https://nakdan.dicta.org.il/\"},{\"name\":\"Nakdimon\",\"tags\":[\"Code\",\"Diacritization / Nikkud / Vocalization\"],\"description\":\"Hebrew diacritizer. Elazar Gershuni and Yuval Pinter: Restoring Hebrew Diacritics Without a Dictionary. `Demo in Replicate <https://replicate.com/elazarg/nakdimon/>`_.\",\"url\":\"https://www.nakdimon.org/\"},{\"name\":\"UNIKUD\",\"tags\":[\"Code\",\"Diacritization / Nikkud / Vocalization\"],\"description\":\" Morris Alper\\'s open-source tool for adding vowel signs (Nikud) to Hebrew text, uses no rule-based logic, built with a CANINE transformer network. An interactive demo is available at `Huggingface Spaces <https://huggingface.co/spaces/malper/unikud>`_. Blog post: `UNIKUD: Adding Vowels to Hebrew Text with Deep Learning <https://towardsdatascience.com/unikud-adding-vowels-to-hebrew-text-with-deep-learning-powered-by-dagshub-56d238e22d3f>`_.\",\"url\":\"https://dagshub.com/morrisalp/unikud\"},{\"name\":\"AlephBERT\",\"tags\":[\"Code\",\"Models\",\"Masked Language Models (MLM)\"],\"description\":\"a large pre-trained language model for Modern Hebrew, publicly available, pre-training on Oscar, Texts of Hebrew tweets, all of Hebrew Wikipedia, published by the OnlpLab team. This model obtains stateof-the- art results on the tasks of segmentation, Part of Speech Tagging, Named Entity Recognition, and Sentiment Analysis. Github: https://github.com/OnlpLab/AlephBERT\",\"url\":\"https://huggingface.co/onlplab/alephbert-base?fbclid=IwAR3gP64XJEDvRcJ9UQm2DIttOnv7Y-6I5R-t7djj9TTTsXlcIA8qyx8PzSQ\"},{\"name\":\"AlephBERTGimmel\",\"tags\":[\"Code\",\"Models\",\"Masked Language Models (MLM)\"],\"description\":\"a new Hebrew pre-trained language model, trained on the same dataset as the previous SOTA Hebrew PLM AlephBERT, consisting od approximiately 2 billion words of text but with a substantially increased vocabulary of 128,000 word pieces. Published as a collaboration of the OnlpLab team and Dicta. Github: https://github.com/Dicta-Israel-Center-for-Text-Analysis/alephbertgimmel\",\"url\":\"https://arxiv.org/pdf/2211.15199.pdf\"},{\"name\":\"HeBERT\",\"tags\":[\"Code\",\"Models\",\"Masked Language Models (MLM)\",\"Sentiment\"],\"description\":\"HeBERT is a Hebrew pretrained language model for Polarity Analysis and Emotion Recognition, published by Dr. Inbal Yahav Shenberger and Avichay Chriqui. It is based on Google\\'s BERT architecture and it is BERT-Base config. HeBert was trained on three dataset: OSCAR, A Hebrew dump of Wikipedia, Emotion User Generated Content (UGC) data that was collected for the purpose of this study. The model was evaluated on downstream tasks: `HebEMO - emotion recognition model <https://huggingface.co/avichr/hebEMO_anticipation?fbclid=IwAR00bGmLoASpEjpCOoWjuZ6q4xhlu6wwZR4Miau2RV2nVsam-o7oVt4jYkY>`_ and `sentiment analysis <https://huggingface.co/avichr/heBERT_sentiment_analysis?fbclid=IwAR1IhvCmosiapbA3iosHc0nJHM6nM-0m7Ew3Zeqw2V4wg-3cWKuB_Qf8OuY>`_. Github: https://github.com/avichaychriqui/HeBERT\",\"url\":\"https://huggingface.co/avichr/heBERT?fbclid=IwAR2Lo9pkN5HLZmtFiFwcIDWyXR9gyP646pyFzNSUUP_djalAkewvB9p8E_o\"},{\"name\":\"TavBERT\",\"tags\":[\"Code\",\"Models\",\"Masked Language Models (MLM)\"],\"description\":\"a BERT-style masked language model over character sequences, published by Omri Keren, Tal Avinari, Prof. Reut Tsarfaty and Dr. Omer Levy.\",\"url\":\"https://github.com/omrikeren/TavBERT\"},{\"name\":\"hebrew-gpt_neo-small\",\"tags\":[\"Code\",\"Models\",\"Causal Language Models (CLM)\"],\"description\":\"Doron Adler\\'s Hebrew text generation model based on EleutherAI\\'s gpt-neo.\",\"url\":\"https://huggingface.co/Norod78/hebrew-gpt_neo-small\"},{\"name\":\"BERT\\'s multilingual model\",\"tags\":[\"Code\",\"Models\",\"Multilingual Models\"],\"description\":\"Trained (also) on Hebrew.\",\"url\":\"https://github.com/google-research/bert/blob/master/multilingual.md\"},{\"name\":\"Universal Language Model Fine-tuning for Text Classification (ULMFiT) in Hebrew\",\"tags\":[\"Code\",\"Models\",\"Multilingual Models\"],\"description\":\"The weights (e.g. a trained model) for a Hebrew version for  Howard\\'s and Ruder\\'s ULMFiT model. Trained on the Hebrew Wikipedia corpus.\",\"url\":\"https://github.com/hanan9m/hebrew_ULMFiT?fbclid=IwAR0wJkoxmaCmhuZnSVOLBo1Mo362v6-66PmXutOr9FhhoItIHoqG_2MzV8E\"},{\"name\":\"Neural Sentiment Analyzer for Modern Hebrew\",\"tags\":[\"Code\",\"Models\",\"Sentiment\"],\"description\":\"This code and dataset provide an established benchmark for neural sentiment analysis for Modern Hebrew.\",\"url\":\"https://github.com/omilab/Neural-Sentiment-Analyzer-for-Modern-Hebrew\"},{\"name\":\"Neural Modeling for Named Entities and Morphology (NEMO2)\",\"tags\":[\"Code\",\"Models\",\"NER\"],\"description\":\"OnlpLab\\'s code and models for neural modeling of Hebrew NER. Described in the TACL paper `Neural Modeling for Named Entities and Morphology (NEMO2) <https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00404/107206/Neural-Modeling-for-Named-Entities-and-Morphology>`_.\",\"url\":\"https://github.com/OnlpLab/NEMO\"},{\"name\":\"MDTEL Code\",\"tags\":[\"Code\",\"Models\",\"NER\"],\"description\":\"Yonatan Bitton\\'s code that recognize medical entities in a Hebrew text.\",\"url\":\"https://github.com/yonatanbitton/mdtel?fbclid=IwAR3Npi5lG4hGy1dcQwdr2RWuEFUArjmQ_bo3FXQ9KhYZUpK5OO67-aT-e5k\"},{\"name\":\"HebSpacy\",\"tags\":[\"Code\",\"Models\",\"NER\"],\"description\":\"A custom spaCy pipeline for Hebrew text including a transformer-based multitask NER model that recognizes 16 entity types in Hebrew, including GPE, PER, LOC and ORG.\",\"url\":\"https://github.com/8400TheHealthNetwork/HebSpacy\"},{\"name\":\"Legal-HeBERT\",\"tags\":[\"Code\",\"Models\",\"Other Deep Learning Tools\"],\"description\":\"a BERT model for Hebrew legal and legislative domains. It is intended to improve the legal NLP research and tools development in Hebrew. Avichay Chriqui, Dr. Inbal Yahav Shenberger and Dr. Ittai Bar-Siman-Tov release two versions of Legal-HeBERT: `The first version <https://huggingface.co/avichr/Legal-heBERT_ft?fbclid=IwAR3K16AoiBYtZlpf2C6TjSstOv7ZuaWLIwCOq93_fRV6bGA3ssDA8NfuHmY>`_ is a fine-tuned model of HeBERT applied on legal and legislative documents. `The second version <https://huggingface.co/avichr/Legal-heBERT?fbclid=IwAR3r-QUCMSdzCoAjomifrk2hCPX7kvGJk47raHHfqBI511QXXchaOkL8rFo>`_ uses HeBERT\\'s architecture guidlines to train a BERT model from scratch.\",\"url\":\"https://github.com/avichaychriqui/Legal-HeBERT?fbclid=IwAR3sFizNJEfPIXm0Agg5HpELUm49v11kfksjes72-Q-9CxMwv8hdR8I5ahg\"},{\"name\":\"BEREL\",\"tags\":[\"Code\",\"Models\",\"Other Deep Learning Tools\"],\"description\":\"BERT Embeddings for Rabbinic-Encoded Language - DICTA\\'s pre-trained language model (PLM) for Rabbinic Hebrew.\",\"url\":\"https://www.dropbox.com/sh/us98wjb178itjk1/AACWu62ffHJ0zk19i77_rV06a?dl=0&fbclid=IwAR0GbzbyASH8bA_lCadXA-2l09oXtg_NNm4QTQ69WDfdtG77gWx9WufB_II\"},{\"name\":\"Verb Inflector\",\"tags\":[\"Code\",\"Code Other\"],\"description\":\"A generation mechanism, created as part of Eran Tomer\\'s (erantom@gmail.com) Master thesis, which produces vocalized and morphologically tagged Hebrew verbs given a non-vocalized verb in base-form and an indication of which pattern the verb follows.\",\"url\":\"https://github.com/NLPH/NLPH_Resources/tree/master/code/VerbInflector\"},{\"name\":\"HebMorph\",\"tags\":[\"Code\",\"Code Other\"],\"description\":\"An open-source effort to make Hebrew properly searchable by various IR software libraries. Includes Hebrew Analyzer for Lucene.\",\"url\":\"https://github.com/synhershko/HebMorph\"},{\"name\":\"Hebrew OCR with Nikud\",\"tags\":[\"Code\",\"Code Other\"],\"description\":\"A program to convert Hebrew text files (without Nikud) to text files with the correct Nikud. Developed by Adi Oz and Vered Shani.\",\"url\":\"https://www.cs.bgu.ac.il/~elhadad/hocr/\"},{\"name\":\"Text-Fabric\",\"tags\":[\"Code\",\"Code Other\"],\"description\":\" A Python package for browsing and processing ancient corpora, focused on the Hebrew Bible Database.\",\"url\":\"https://dans-labs.github.io/text-fabric/\"},{\"name\":\"The Automatic Hebrew Transcriber\",\"tags\":[\"Code\",\"Code Other\"],\"description\":\"Automatically transcribes text from Hebrew audio and video files.\",\"url\":\"http://hebrew-transcriber.online/\"},{\"name\":\"word2word\",\"tags\":[\"Code\",\"Code Other\"],\"description\":\"Easy-to-use word-to-word translations for 3,564 language pairs. Hebrew is one of the 62 supported language, and thus word-to-word translation to/from Hebrew is supported for 61 languages.\",\"url\":\"https://github.com/Kyubyong/word2word\"},{\"name\":\"SPMRL\",\"tags\":[\"Code\",\"Code Other\"],\"description\":\"converts YAP\\'s output from the SPMRL scheme to UD v2.\",\"url\":\"https://github.com/shovalsa/SPMRL-to-UD\"},{\"name\":\"Eyfo\",\"tags\":[\"Code\",\"Commercial services\"],\"description\":\"A commercial engine for search and entity tagging in Hebrew.\",\"url\":\"https://ey.fo/search\"},{\"name\":\"Melingo\\'s ICA (Intelligent Content Analysis)\",\"tags\":[\"Code\",\"Commercial services\"],\"description\":\"A text analysis and textual categorized entity extraction API for Hebrew, Arabic and Farsi texts.\",\"url\":\"https://melingo.com/text-analysis/morfix_insights/\"},{\"name\":\"Genius\",\"tags\":[\"Code\",\"Commercial services\"],\"description\":\"Automatic analysis of free text in Hebrew.\",\"url\":\"https://www.genius.co.il\"},{\"name\":\"AlmaReader\",\"tags\":[\"Code\",\"Commercial services\"],\"description\":\"Online text-to-speech service for Hebrew.\",\"url\":\"https://app.almareader.com/\"},{\"name\":\"LightTag\",\"tags\":[\"Tagging Tools\"],\"description\":\"A tool for managing annotation projects. Handles right-to-left and part-of-word marking. `Tutorial video here <https://www.youtube.com/watch?v=eTlrTC_n_yg>`_.\",\"url\":\"nlph.lighttag.io\"},{\"name\":\"Recogito\",\"tags\":[\"Tagging Tools\"],\"description\":\"A tool for linked data annotation.\",\"url\":\"http://recogito.pelagios.org/\"},{\"name\":\"CATMA\",\"tags\":[\"Tagging Tools\"],\"description\":\"A web-based tool for research and collaboration over text data. Handles right-to-left and part-of-word marking.\",\"url\":\"http://catma.de/ See the system itself here: http://portal.catma.de/catma/ And the code here: https://github.com/mpetris/catma\"},{\"name\":\"WebAnno\",\"tags\":[\"Tagging Tools\"],\"description\":\"Web-based. Support RTL and project management. Repository: https://github.com/webanno/webanno\",\"url\":\"https://webanno.github.io/\"},{\"name\":\"Arethusa\",\"tags\":[\"Tagging Tools\"],\"description\":\"A backend-independent client-side annotation framework. `Repository here <https://github.com/alpheios-project/arethusa>`_.\",\"url\":\"https://www.perseids.org/tools/arethusa/app/#/\"},{\"name\":\"rasa-nlu-trainer\",\"tags\":[\"Tagging Tools\"],\"description\":\"A tool to edit training examples for `rasa NLU <https://github.com/rasahq/rasa_nlu>`_. Handles right-to-left and part-of-word marking.\",\"url\":\"https://github.com/RasaHQ/rasa-nlu-trainer\"},{\"name\":\"brat\",\"tags\":[\"Tagging Tools\"],\"description\":\"An online environment for collaborative text annotation. Does not support right-to-left. `Repository here <https://github.com/nlplab/brat>`_.\",\"url\":\"http://brat.nlplab.org/\"},{\"name\":\"openNLP\",\"tags\":[\"Tagging Tools\"],\"description\":\"OpenNLP has a tagging tool.\",\"url\":\"https://opennlp.apache.org/\"},{\"name\":\"opeNER\",\"tags\":[\"Tagging Tools\"],\"description\":\"opeNER has a tagging tool.\",\"url\":\"http://www.opener-project.eu/\"},{\"name\":\"pybossa\",\"tags\":[\"Tagging Tools\"],\"description\":\"A framework for crowdsourcing of data analysis and enrichment tasks. `GitHub <https://github.com/Scifabric/pybossa>`_.\",\"url\":\"http://pybossa.com/\"},{\"name\":\"TextThrasher\",\"tags\":[\"Tagging Tools\"],\"description\":\"A crowdsourced text annotator. Built with React and Redux (possibly also with pybossa). \",\"url\":\"https://github.com/Goodly/TextThresher\"},{\"name\":\"SHEBANQ\",\"tags\":[\"Tagging Tools\"],\"description\":\"System for HEBrew Text: ANnotations for Queries and Markup. SHEBANQ is an online environment for studying the Hebrew Bible.\",\"url\":\"https://shebanq.ancient-data.org/\"},{\"name\":\"doccano\",\"tags\":[\"Tagging Tools\"],\"description\":\"an open source text annotation tool for humans. It provides annotation features for text classification, sequence labeling and sequence to sequence tasks. So, you can create labeled data for sentiment analysis, named entity recognition, text summarization and so on.\",\"url\":\"https://github.com/doccano/doccano\"},{\"name\":\"Hebrew Dependency Parsing: Initial Results\",\"tags\":[\"Papers\",\"Corpora, Lexicon and Dictionary Generation\"],\"writers\":[\"Yoav Goldberg\",\"Michael Elhadad\"],\"description\":\"IWPT-2009 (Short Paper)\",\"url\":\"https://www.cs.bgu.ac.il/~yoavg/publications/iwpt2009depbaseline.pdf\"},{\"name\":\"A Computational Lexicon of Contemporary Hebrew\",\"tags\":[\"Papers\",\"Corpora, Lexicon and Dictionary Generation\"],\"writers\":[\"Alon Itai\",\"Shuly Wintner\",\"Shlomo Yona\"],\"description\":\"Proceedings of The fifth international conference on Language Resources and Evaluation (LREC-2006). Genoa, Italy.\",\"url\":\"http://www.cs.technion.ac.il/~itai/publications/NLP/lexicon-final.pdf?fbclid=IwAR1bBcwEA7A__fWG1a1fwDdcqKZj375YcMdCrhYrdBkUw_SZTrB8flHnf9M\"},{\"name\":\"Language Resources for Hebrew.\",\"tags\":[\"Papers\",\"Corpora, Lexicon and Dictionary Generation\"],\"writers\":[\"Alon Itai\",\"Shuly Wintner\"],\"description\":\"Language Resources and Evaluation 42(1):75-98, March 2008.\",\"url\":\"http://cs.haifa.ac.il/~shuly/publications/lre4h.pdf\"},{\"name\":\"Hebrew WordNet: A Test Case of Aligning Lexical Databases Across Languages.\",\"tags\":[\"Papers\",\"Corpora, Lexicon and Dictionary Generation\"],\"writers\":[\"Noam Ordan\",\"Shuly Wintner\"],\"description\":\"International Journal of Translation 19(1):39-58, 2007.\",\"url\":\"http://cs.haifa.ac.il/~shuly/publications/wordnet.pdf\"},{\"name\":\"Representing Natural Gender in Multilingual Lexical Databases.\",\"tags\":[\"Papers\",\"Corpora, Lexicon and Dictionary Generation\"],\"writers\":[\"Noam Ordan\",\"Shuly Wintner\"],\"description\":\"International Journal of Lexicography 18(3):357-370, September 2005.\",\"url\":\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.8099&rep=rep1&type=pdf\"},{\"name\":\"Building a Tree-Bank of Modern Hebrew Text.\",\"tags\":[\"Papers\",\"Corpora, Lexicon and Dictionary Generation\"],\"writers\":[\"Khalil Sima\\'an\",\"Alon Itai\",\"Yoad Winter\",\"Alon Altman\",\"Noa Nativ\"],\"description\":\"Traitment Automatique des Langues, 42, 347-380. 2001.\",\"url\":\"http://www.cs.technion.ac.il/~winter/Corpus-Project/paper.pdf\"},{\"name\":\"A Finite-State Morphological Grammar of Hebrew.\",\"tags\":[\"Papers\",\"Morphological Analysis & Disambiguation\"],\"description\":\"\",\"writers\":[\"Shlomo Yona\",\"Shuly Wintner\"],\"url\":\"http://cs.haifa.ac.il/~shuly/publications/morphgram.pdf\"},{\"name\":\"Hebrew Morphological Disambiguation: An Unsupervised Stochastic Word-based Approach.\",\"tags\":[\"Papers\",\"Morphological Analysis & Disambiguation\"],\"description\":\"\",\"writers\":[\"Meni Adler\"],\"url\":\"https://www.cs.bgu.ac.il/~adlerm/dat/thesis.pdf\"},{\"name\":\"Part-of-Speech Tagging of Modern Hebrew Text.\",\"tags\":[\"Papers\",\"Morphological Analysis & Disambiguation\"],\"description\":\"\",\"writers\":[\"Roy Bar-Haim\",\"Khalil Sima\\'an\",\"Yoad Winter\"],\"url\":\"http://www.cs.technion.ac.il/~barhaim/MorphTagger/HebrewPOSTaggingNLE.pdf\"},{\"name\":\"Data-Driven Morphological Analysis and Disambiguation for Morphologically Rich Languages and Universal Dependencies\",\"tags\":[\"Papers\",\"Morphological Analysis & Disambiguation\"],\"description\":\"\",\"writers\":[\"Amir More\",\"Reut Tsarfaty\"],\"url\":\"http://aclweb.org/anthology/C16-1033\"},{\"name\":\"A Characterwise Windowed Approach to Hebrew Morphological Segmentation\",\"tags\":[\"Papers\",\"Morphological Analysis & Disambiguation\"],\"description\":\"\",\"writers\":[\"Amir Zeldes\"],\"url\":\"http://aclweb.org/anthology/W18-5811\"},{\"name\":\"The Interplay of Semantics and Morphology in Word Embeddings\",\"tags\":[\"Papers\",\"Word Embeddings\"],\"writers\":[\"Oded Avraham\",\"Yoav Goldberg\"],\"description\":\"Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2017).\",\"url\":\"https://arxiv.org/abs/1704.01938\"},{\"name\":\"Named Entities Tagging Guidelines for Hebrew\",\"tags\":[\"Papers\",\"Methodology\"],\"writers\":[\"Michael Elhadad\",\"Naama Ben-Mordecai\"],\"description\":\"Written during M.Sc. research by Naama Ben-Mordecai advised by Dr. Michael Elhadad at the Department of Computer Science, Ben-Gurion University.\",\"url\":\"https://github.com/NLPH/NLPH_Resources/blob/master/methodology/hebrew_named_entity_tagging_guidelines.doc?raw=true\"},{\"name\":\"Automatic Hebrew Text Vocalization\",\"tags\":[\"Papers\",\"Other NLP Papers\"],\"writers\":[\"Eran Tomer\"],\"description\":\"Thesis submitted as part of the requirements for the M.Sc. degree of Ben-Gurion University of the Negev, 2012. Broken Link\",\"url\":\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.357.7101&rep=rep1&type=pdf\"},{\"name\":\"The NLPH Facebook Group\",\"tags\":[\"Courses, presentations and meetups\",\"Meetup & Discussion Groups\"],\"description\":\"Active Facebook Group\",\"url\":\"https://www.facebook.com/groups/157877988136954/\"},{\"name\":\"The Israeli Natural Language Processing Meetup\",\"tags\":[\"Courses, presentations and meetups\",\"Meetup & Discussion Groups\"],\"description\":\"\",\"url\":\"https://www.meetup.com/The-Israeli-Natural-Language-Processing-Meetup/\"},{\"name\":\"Bar Ilan University\\'s NLP course\",\"tags\":[\"Courses, presentations and meetups\",\"Specific Talks\"],\"description\":\"NLP course\",\"url\":\"https://www.youtube.com/playlist?list=PLM96W_EHEqh78zJ0bPqT3Wy8DPHbJU-Zh\"},{\"name\":\"ONLP April 2019 Meetup lecture slides\",\"tags\":[\"Courses, presentations and meetups\",\"Specific Talks\"],\"description\":\"Meetup lecture slides\",\"url\":\"https://drive.google.com/file/d/1YxZeeFjQJzdJQKabzSelm-ojm1LfM2Sy/view?usp=sharing&fbclid=IwAR3Y9a3BiHNxmxGyL65Vq_KKqCNkmyZnP_0dKTzbk_ZQPzfu6yb5BHbGsyw\"},{\"name\":\"Big DataNights NLP 2020\",\"tags\":[\"Courses, presentations and meetups\",\"Specific Talks\"],\"description\":\"\",\"url\":\"https://www.youtube.com/watch?v=8YYnkd50LwM&list=PLZYkt7161wEJ8zW_TgD3v0r7GwkXgFFWb\"}]')},a535:function(e,t,a){\"use strict\";a(\"a9b5\")},a9b5:function(e,t,a){},ae61:function(e,t,a){\"use strict\";a.r(t);var o=function(){var e=this,t=e._self._c;return t(\"div\",[t(\"h1\",[e._v(\"All Hebrew NLP Items\")]),t(\"div\",{staticClass:\"filters\"},[t(\"label\",[e._v(\"\\n       Search Your Item\\n    \"),t(\"input\",{directives:[{name:\"model\",rawName:\"v-model\",value:e.searchQuery,expression:\"searchQuery\"}],attrs:{type:\"text\",placeholder:\"Search items\"},domProps:{value:e.searchQuery},on:{input:function(t){t.target.composing||(e.searchQuery=t.target.value)}}})]),t(\"br\"),t(\"label\",[e._v(\"\\n      Filter by tag:\\n      \"),t(\"select\",{directives:[{name:\"model\",rawName:\"v-model\",value:e.selectedTag,expression:\"selectedTag\"}],on:{change:[function(t){var a=Array.prototype.filter.call(t.target.options,(function(e){return e.selected})).map((function(e){var t=\"_value\"in e?e._value:e.value;return t}));e.selectedTag=t.target.multiple?a:a[0]},e.filterItems]}},[t(\"option\",{attrs:{value:\"all\"}},[e._v(\"All\")]),e._l(e.tags,(function(a){return t(\"option\",{domProps:{value:a}},[e._v(e._s(a))])}))],2)]),t(\"br\")]),t(\"div\",{staticClass:\"items-section\"},e._l(e.itemsToDisplay,(function(a,o){return t(\"div\",{key:a.name,staticClass:\"item\"},[t(\"h3\",{staticClass:\"item-name\"},[e._v(e._s(a.name))]),t(\"p\",[e._v(e._s(a.tags.join(\", \")))]),t(\"a\",{staticClass:\"linkToRef\",attrs:{href:a.url,target:\"_blank\"}},[e._v(\"Link to source\")]),t(\"br\"),t(\"br\"),t(\"div\",[t(\"transition\",{attrs:{duration:{enter:800,leave:100},name:\"fade\",mode:\"out-in\"}},[a.expanded?t(\"div\",{staticClass:\"expandable\"},[e._v(\"\\n            \"+e._s(a.description)+\"\\n            \"),t(\"br\"),t(\"br\")]):e._e()]),t(\"button\",{staticClass:\"expand-button\",on:{click:function(t){return e.toggleExpanded(a.name)}}},[e._v(e._s(a.buttonText))])],1)])})),0)])},i=[],r={data(){return{searchQuery:\"\",expanded:!1,items:[],tags:[\"Corpora\",\"Code\",\"Linguistic Resources\",\"Papers\",\"Courses, presentations and meetups\",\"Tagging Tools\"],selectedTag:\"all\"}},computed:{itemsToDisplay(){let e=this.items.map(e=>({...e,buttonText:e.expanded?\"Collapse\":\"Expand\"}));return e=e.filter(e=>e.name.toLowerCase().includes(this.searchQuery.toLowerCase())),\"all\"===this.selectedTag?e:e.filter(e=>e.tags.includes(this.selectedTag))}},beforeMount(){let e=a(\"9a57\").map(e=>({...e,expanded:!1}));this.items=e},methods:{filterItems(){},toggleExpanded(e){const t=this.items.find(t=>t.name===e);t.expanded=!t.expanded}}},s=r,n=(a(\"a535\"),a(\"2877\")),l=Object(n[\"a\"])(s,o,i,!1,null,null,null);t[\"default\"]=l.exports}}]);","extractedComments":[]}