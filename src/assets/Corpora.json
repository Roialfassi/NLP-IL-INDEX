[
    {"name": "Hebrew Wikipedia dumps", "tags": ["Corpora", "Structured Corpora", "Unannotated Corpora"], "description": "Wikipedia, the free encyclopedia, publishes dumps of its content as XML files on a monthly basis.", "url": "https://dumps.wikimedia.org/hewiki/latest/"},
    {"name": "hewikibooks dump", "tags": ["Corpora", "Structured Corpora", "Unannotated Corpora"], "description": "Wikimedia dump service", "url": "https://dumps.wikimedia.org/hewikibooks/20220520/"},
    {"name": "Wikipedia Corpora used for AlephBERT", "tags": ["Corpora", "Structured Corpora", "Unannotated Corpora"], "description": "The texts in all of Hebrew Wikipedia was also extracted to pre-train OnlpLab's AlephBERT, using `Attardi's Wikiextractor", "url": "https://github.com/OnlpLab/AlephBERT/tree/main/data/wikipedia"},
    {"name": "OSCAR", "tags": ["Corpora", "Structured Corpora", "Unannotated Corpora"], "description": "OSCAR or Open Super-large Crawled Aggregated coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the Ungoliant architecture.", "url": "https://oscar-corpus.com/"},
    {"name": "Project Ben Yehuda public dumps", "tags": ["Corpora", "Structured Corpora", "Unannotated Corpora"], "description": "A repository containing dumps of thousands of public domain works in Hebrew, from `Project Ben-Yehuda, in plaintext UTF-8 files, with and without diacritics (nikkud), and in HTML files.", "url": "https://github.com/projectbenyehuda/public_domain_dump"},
    {"name": "CC100", "tags": ["Corpora", "Structured Corpora", "Unannotated Corpora"], "description": "This corpus is an attempt to recreate the dataset used for training XLM-R. This corpus comprises of monolingual data for 100+ languages, including Hebrew. This was constructed using the urls and paragraph indices provided by the CC-Net repository by processing January-December 2018 Commoncrawl snapshots.", "url": "https://data.statmt.org/cc-100/?fbclid=IwAR2czQ8iHkINcK3oAoYTtIRcsj0TaiKOedor6S3Xzb-9-djTnHrK5D69lD0"},
    {"name": "Sefaria", "tags": ["Corpora", "Structured Corpora", "Unannotated Corpora"], "description": "Structured Jewish texts and metadata with free public licenses, exported from Sefaria's database.", "url": "https://github.com/Sefaria/Sefaria-Export/"},
    {"name": "Hebrew songs lyrics", "tags": ["Corpora", "Structured Corpora", "Unannotated Corpora"], "description": "15,000 israeli songs scrapped from `Shironet`_ website and contains 167 different singers. Contains only hebrew charecters.", "url": "https://www.kaggle.com/datasets/guybarash/hebrew-songs-lyrics?fbclid=IwAR1Tji-2oWxeB54wM3YDVViMG7xTM6000yiov_H1AZTQVRiP9VfmiXkyYu4"},
    
    {"name": "Knesset 2004-2005", "tags": ["Corpora", "Annotated Datasets", "Annotated by Parts of Speech"], "description": "A corpus of transcriptions of Knesset (Israeli parliament) meetings between January 2004 and November 2005. Includes tokenized and morphologically tagged versions of most of the documents in the corpus.", "url": "https://github.com/NLPH/knesset-2004-2005"},
    {"name": "The GOV.il Corpus", "tags": ["Corpora", "Annotated Datasets", "Annotated by Parts of Speech"], "description": " קורפוס השפה העברית -    מאגר שפה מתויגת, חלק מפרוייקט קורפוס השפה העברית של רשות התקשוב הממשלתי. התיוג מבוצע על ידי האקדמיה ללשון העברית. תוצר ראשון זה כולל 600 משפטים מתוייגים", "url": "https://data.gov.il/dataset/corpus"},

    {"name": "NEMO", "tags": ["Corpora", "Annotated Datasets", "Annotated by Entites"], "description": "Named Entity (NER) annotations of the Hebrew Treebank (Haaretz newspaper) corpus, including: morpheme and token level NER labels, nested mentions, and more. The following entity types are tagged: Person, Organization, Geo-Political Entity, Location, Facility, Work-of-Oart, Event, Product, Language.", "url": "https://github.com/OnlpLab/NEMO-Corpus"},
    {"name": "MDTEL", "tags": ["Corpora", "Annotated Datasets", "Annotated by Entites"], "description": "A dataset of posts from the www.camoni.co.il, tagged with medical entities from the UMLS, and a code that recognize medical entities in the Hebrew text.", "url": "https://github.com/yonatanbitton/mdtel?fbclid=IwAR3Npi5lG4hGy1dcQwdr2RWuEFUArjmQ_bo3FXQ9KhYZUpK5OO67-aT-e5k"},
    {"name": "Ben-Mordecai and Elhadad's Corpus", "tags": ["Corpora", "Annotated Datasets", "Annotated by Entites"], "description": "Newspaper articles in different fields: news, economy, fashion and gossip. The following entity types are tagged: entity names (person, location, organization), temporal experssion (date, time) and number experession (percent, money).", "url": "https://www.cs.bgu.ac.il/~elhadad/nlpproj/naama/"},

    {"name": "ParaShoot", "tags": ["Corpora", "Annotated Datasets", "Question Answering Datasets"], "description": "A Hebrew question and answering dataset in the style of SQuAD created by Omri Keren and Omer Levy. ParaShoot is based on articles scraped from Wikipedia. The dataset contains 3K crowdsource-annotated pairs of questions and answers, in a setting suitable for few-shot learning.", "url": "https://github.com/omrikeren/ParaShoot"},
    {"name": "tdklab", "tags": ["Corpora", "Annotated Datasets", "Question Answering Datasets"], "description": "translated (by google translation API) SQUAD dataset from English to Hebrew. The translation process included fixation and removal of bad translations.", "url": "https://github.com/TechnionTDK/hebwiki-qa?fbclid=IwAR0Xbq-s1xu2gH8BS35zgFgNCeHIJ6wVZws4gqHCZ_VucbgiIngpHNTWApU"},

    {"name": "Hebrew-Sentiment-Data Amram et al", "tags": ["Corpora", "Annotated Datasets", "Sentiment"], "description": "A sentiment analysis benchmark (positive, negative and neutral sentiment) for Hebrew, based on 12K social media comments, containing two instances of input items: token-based and morpheme-based. A cleaned version of the Hebrew Sentiment dataset - a test-train data leakage was cleaned.", "url": "https://github.com/OnlpLab/Hebrew-Sentiment-Data>"},
    {"name": "Emotion User Generated Content (UGC)", "tags": ["Corpora", "Annotated Datasets", "Sentiment"], "description": "{MIT} - collected for HeBERT model and includes comments posted on news articles collected from 3 major Israeli news sites, between January 2020 to August 2020. The total size of the data is ~150 MB, including over 7 millions words and 350K sentences. ~2000 sentences were annotated by crowd members (3-10 annotators per sentence) for overall sentiment (polarity) and eight emotions.", "url": "https://github.com/avichaychriqui/HeBERT?fbclid=IwAR0GVuSWEvYWimkV4Z22h6-GSEznY2G2eIRz7gDGcAcHT3hB4vgUkxkBCPg"},

    {"name": "Emotion User Generated Content", "tags": ["Corpora", "Annotated Datasets", "Emotion"], "description": "{MIT} - collected for HeBERT model and includes comments posted on news articles collected from 3 major Israeli news sites, between January 2020 to August 2020. The total size of the data is ~150 MB, including over 7 millions words and 350K sentences. ~2000 sentences were annotated by crowd members (3-10 annotators per sentence) for overall sentiment (polarity) and eight emotions: anger, disgust, expectation , fear, happy, sadness, surprise and trust.", "url": "https://github.com/avichaychriqui/HeBERT?fbclid=IwAR0GVuSWEvYWimkV4Z22h6-GSEznY2G2eIRz7gDGcAcHT3hB4vgUkxkBCPg"},
    
    {"name": "Knesset Topic Classification", "tags": ["Corpora", "Annotated Datasets", "Topic Classification"], "description": "This data was collected as a part of Nitzan Barzilay's project and contains about 2,700 quotes from Knesset meetings, manually classified into eight topics: education, Covid-19, welfare, economic, women and LGBT, health, security, internal security.", "url": "https://github.com/NitzanBarzilay/KnessetTopicClassification/"},
    
    {"name": "The HUJI Corpus of Spoken Hebrew", "tags": ["Corpora", "Annotated Datasets", "Recorded Spoken Hebrew"], "description": "The corpus project, created by Dr Michal Marmorstein, Nadav Matalon, Amir Efrati, Itamar Folman and Yuval Geva, and hosted by the Hebrew University of Jerusalem (HUJI), aims at documenting naturally occurring speech and interaction in Modern Hebrew. Data come from telephone conversations recorded during the years 2020–2021. Data annotation followed standard methods of Interactional Linguistics (Couper-Kuhlen and Selting 2018). Audio files and transcripts were made freely accessible online.", "url": "https://huji-corpus.com/"},
    {"name": "CoSIH - The Corpus of Spoken Hebrew", "tags": ["Corpora", "Annotated Datasets", "Recorded Spoken Hebrew"], "description": "The Corpus of Spoken Israeli Hebrew (CoSIH) is a database of recordings of spoken Israeli Hebrew", "url": "http://cosih.com/table-3.html"},
    {"name": "MaTaCOp", "tags": ["Corpora", "Annotated Datasets", "Recorded Spoken Hebrew"], "description": "a corpus of Hebrew dialogues within the Map Task framework (allowed for non-commercial research and teaching purposes only)", "url": "https://www.openu.ac.il/en/academicstudies/matacop/pages/default.aspx"},
    
    
    {"name": "Eran Tomer's Digital Vocalized Text Corpus", "tags": ["Corpora", "Annotated Datasets", "Other Datasets"], "description": "A corpus of digital vocalized Hebrew texts created by Eran Tomer as part of his Master thesis. The corpus is found in the ``resources`` folder.", "url": "https://www.dropbox.com/sh/rlg0k0flz0675ho/AADvfxmY3SN8lqmkGAWr0hd2a?dl=0"},
    {"name": "The SVLM Hebrew Wikipedia Corpus", "tags": ["Corpora", "Annotated Datasets", "Other Datasets"], "description": "A corpus of 50K sentences from Hebrew Wikipedia chosen to ensure phoneme coverage for the purpose of a sentence recording project.", "url": "https://github.com/NLPH/SVLM-Hebrew-Wikipedia-Corpus"},
   
    {"name": "The MILA corpora collection", "tags": ["Corpora", "Corpora Sources"], "description": "The MILA center has 20 different corpora available for free for non-commercial use. All are available in plain text format, and most have tokenized, morphologically-analyzed, and morphologically-disambiguated versions available too.", "url": "http://www.mila.cs.technion.ac.il/resources_corpora.html"},
    {"name": "JPress", "tags": ["Corpora", "Corpora Sources"], "description": "`The National Library http://web.nli.org.il offers a collection of Jewish newspapers published in various countries, languages, and time periods, including digital versions and full-text search. The texts are published under a custom Terms of Use document http://web.nli.org.il/sites/JPress/English/about/Pages/tems-of-use.aspx that prohibits commercial use, and additionally requires checking the copyright status and receiving permission from the copyright-holder of the work for any use requiring such permission according to the Copyright Law.", "url": "http://www.jpress.org.il"},
    {"name": "DICTA", "tags": ["Corpora", "Corpora Sources"], "description": "Analytical tools for Jewish texts. They also have a `GitHub organization`", "url": "http://dicta.org.il"},
    {"name": "Sefaria Corpra", "tags": ["Corpora", "Corpora Sources"], "description": "{Various} - A Living Library of Jewish Texts. 3,000 years of Jewish texts in Hebrew and English translation.", "url": "https://www.sefaria.org.il/"},
    {"name": "HaArchion", "tags": ["Corpora", "Corpora Sources"], "description": "Recording of various Hebrew prose and poetry being read.", "url": "http://www.haarchion.co.il/"},
    {"name": "ThinkIL", "tags": ["Corpora", "Corpora Sources"], "description": "An archive of the writings of Zvi Yanai.", "url": "http://thinkil.co.il/the-website/credits_and_sponsors/"}

]